---
title: "174 Stock Analysis Project"
output:
  html_document: default
  pdf_document: default
date: "2023-03-01"
---
# Comparing Amazon, Microsoft, Nvidia, and Google stocks
#### 174 Project
#### By: Jae Yun


#### Introduction: 

The stock market is one of the most fascinating fields, as many stocks within the same industry follow the same price pattern. This is especially true in the technology industry where companies like as Amazon, Microsoft, Nvidia, and Google have become dominant companies, as they hold some of the largest market caps in the world. These companies have all experienced significant growth over the past decade, and the technology has outgrown all other industries and became the leading sector in the past few decades. 

It is interesting to study these stocks in the industry because of the fact that we can determine the entire technology industry using just these four stocks. However, the main idea is that we can to make forecasts using the stocks and determine if each of the stocks are related to their technological counterparts, as it is a crucial component of a stock market analyst in predicting the future of the stock. While analyzing the technology industry as a whole can provide valuable insights into overall trends and economic conditions, predicting the performance of individual stocks can help investors and analysts make more informed decisions about their specific investments, especially ones as stable as Amzn, Msft, Nvda, and Googl. 

While many companies prefer to diversify their stock portfolio, some companies tend invest in individual stocks from a certain industry as a way to generate higher returns, especially if they have the knowledge about the certain company they are investing in. This strategy is a high-reward type situation that would help the company thrive but also pose high risks to due the volatility of individual stocks and their strong reactions from current market trends. However, the time period from 2010 to 2019 was a relatively stable growth period in terms of political and economical stability, and thus, companies would have chosen a riskier approach during this decade. 

Thus, we play the role of a data analyst in a company following a riskier investing scheme, with goal of utilizing each individual stock to predict their future performance and see which of the four stocks have a higher return of investment within the next year between the beginning of 2019 to end of 2019 based on the data from 2010 to the end of 2018. We want to see which of the four stocks will have the highest predicted performance of the 2019 year, in hopes that we can use the same model to predict the 2020 year.

For our project, we will use four weekly prices of Amazon, Microsoft, NVIDIA, and Google from the 10 year time frame between January 1st, 2010, to January 1st, 2020, and compare the datasets to each other. Our datasets were retrieved from Yahoo Finance, with 522 observations representing each week's price opening for each of the four tech stocks.

We wanted to find a certain time frame in which a major event did not occur, so that we have a more reliable prediction that is based on the trend and seasonality of our data throughout the years, and rather not based on certain events, such as the coronavirus pandemic, the Russo-Ukrainian war, or the 2008 recession. Albeit the time frame from 2010 to 2020 had some events. This is a biased dataset because we have knowledge of the past and the events that have occured, but we want to consider our model forecasts if we hypothetically did not have any major stock-changing events since we want a more technical analysis/forecasts of the stock rather than having to consider actual events, which we can't really quantify in our time series predictions. 

## FORMULAS USED: 

#### Augmented Dickey-Fuller (ADF Test): 
$$\Delta y_t = \alpha + \beta t + \gamma y_{t-1} + \delta_1 \Delta y_{t-1} + \cdots + \delta_{p-1} \Delta y_{t-p+1} + \varepsilon_t$$

where $\Delta y_t$ is the first difference of the time series at time $t$, $\alpha$ is a constant term, $\beta$ is the coefficient of a linear time trend, and $\gamma$ is the coefficient of the lagged value $y_{t-1}$. The terms $\delta_i$ are the coefficients of the lagged first differences, up to a maximum lag of $p-1$. The error term $\varepsilon_t$ is assumed to be white noise.

#### Decomposition: Y(t) = T(t) + S(t) + R(t) where:
*Y(t) is the observed value of the time series at time t =  T(t) + S(t) + R(t)

*T(t) is the trend component of the time series at time t
$T_t = f(t)$


*S(t) is the seasonal component of the time series at time 
*$S_t = \sum_{i=1}^n s_i$

*R(t) is the residual or random component of the time series at time t
*$R_t = Y_t - T_t - S_t$



#### ACF:
$$\text{ACF}(k) = \frac{\sum_{t=k+1}^n (Y_t - \bar{Y})(Y_{t-k} - \bar{Y})}{\sum_{t=1}^n (Y_t - \bar{Y})^2}$$

where $k$ is the lag, $n$ is the number of observations in the time series, $Y_t$ is the observed value at time $t$, and $\bar{Y}$ is the sample mean of the time series.




#### PACF: 
$$\rho_0 = 1$$

$$\rho_k = \frac{\text{cov}(Y_t, Y_{t-k})}{\text{var}(Y_t)} - \sum_{j=1}^{k-1} \phi_j \rho_{k-j}$$

where $\rho_k$ is the partial autocorrelation at lag $k$, $\text{cov}(Y_t, Y_{t-k})$ is the covariance between $Y_t$ and $Y_{t-k}$, $\text{var}(Y_t)$ is the variance of $Y_t$, $\phi_j$ is the estimated coefficient of the autoregressive (AR) model at lag $j$, and $k$ is the maximum lag for which the PACF is computed.

#### Differencing:

$y't = y_t - y{t-52}$ For our 52 weekly period differencing

$y't = y_t - y{t-1}$ For taking the first difference

where $y_t$ is the observed value of the time series at time $t$, and $y'_{t}$ is the differenced value of the time series at time $t$.

#### Sarima Model:

$$(1 - \phi_1 B - \cdots - \phi_p B^p)(1 - \Phi_1 B^s - \cdots - \Phi_P B^{sP})^d (y_t - \mu)$$
$$= (1 + \theta_1 B + \cdots + \theta_q B^q)(1 + \Theta_1 B^s + \cdots + \Theta_Q B^{sQ})\varepsilon_t$$
where $y_t$ is the observed value of the time series at time $t$, $\mu$ is the mean of the time series, $\varepsilon_t$ is the error term at time $t$, and $B$ is the backshift operator. The parameters $p$, $d$, and $q$ correspond to the order of the autoregressive (AR), integrated (I), and moving average (MA) components, respectively. The parameters $P$, $D$, and $Q$ correspond to the order of the seasonal AR, seasonal I, and seasonal MA components, respectively. The parameter $s$ represents the length of the seasonal cycle.

The $\phi$ and $\theta$ parameters are the coefficients of the AR and MA terms, respectively, while the $\Phi$ and $\Theta$ parameters are the coefficients of the seasonal AR and seasonal MA terms


#### Ljung-Box Test

$$Q = n(n+2) \sum_{k=1}^h \frac{\hat{\rho}_k^2}{n-k}$$

where $Q$ is the test statistic, $n$ is the sample size, $h$ is the number of lags being tested, and $\hat{\rho}_k$ is the sample autocorrelation at lag $k$. The null hypothesis of the test is that the autocorrelations up to lag $h$ are equal to zero, indicating that the time series is a white noise process. The alternative hypothesis is that the autocorrelations are not equal to zero, indicating the presence of serial correlation in the data. The test statistic $Q$ follows a chi-squared distribution with $h-p$ degrees of freedom, where $p$ is the number of parameters estimated in the time series model.

#### Box-Pierce Test
$$Q^* = n \sum_{k=1}^h \hat{\rho}_k^2$$

where $Q^*$ is the test statistic, $n$ is the sample size, $h$ is the number of lags being tested, and $\hat{\rho}_k$ is the sample autocorrelation at lag $k$. The null hypothesis of the test is that the autocorrelations up to lag $h$ are equal to zero, indicating that the time series is a white noise process. The alternative hypothesis is that the autocorrelations are not equal to zero, indicating the presence of serial correlation in the data.

The test statistic $Q^*$ follows an approximately chi-squared distribution with $h-p$ degrees of freedom, where $p$ is the number of parameters estimated in the time series model.

## Data Analysis: 

The 5 V's of our Data:
Volume: We have a significant amount of data, ranging from weekly data for a span of 10 years in the stock market. Thus, we can use this vast amount of data to make our predictions more effectively
Velocity: Our velocity of our data is the weekly aspect 
Variety: Albeit having 4 of some of the largest stocks in the technology industry, we have a variety in the sense that these prices are all mutually exclusive to their own stock, and each company has different behaviors.
Veracity: Since we are working with data retrieved from Yahoo Finance, we have pinpointed accuracy in our data because these prices were reflected on the actual stock market prices during these times. We have a very strong accuracy that our data is true.
Value: By analyzing this data, we can determine trends and make analysis of the data as well as look into the future of how the data will perform, and also use this forecasting to predict other aspects of the stock market or economy, since these powerhouse stocks are highly impactful of the tech industry.


Now, we can begin importing our data from yahoo, read csv, and plot the time series data:

```{r, echo = F, warning = F, include = F}
library(dplyr)
library(forecast)
library(astsa)
library(ROCR)
knitr::opts_chunk$set(fig.width=12, fig.height=6) 
```

```{r, echo = F}
NVDA_Weekly <- readr::read_csv("~/Downloads/Jae Yun 9468901_RmrkDown_Data/NVDA (1).csv",show_col_types = FALSE)
GOOGL_Weekly <- readr::read_csv("~/Downloads/Jae Yun 9468901_RmrkDown_Data/GOOGL (1).csv",show_col_types = FALSE)
MSFT_Weekly <- readr::read_csv("~/Downloads/Jae Yun 9468901_RmrkDown_Data/MSFT (2).csv",show_col_types = FALSE)
AMZN_Weekly <- readr::read_csv("~/Downloads/Jae Yun 9468901_RmrkDown_Data/AMZN (5).csv",show_col_types = FALSE)


df_nvda <- data.frame(Date = NVDA_Weekly$Date, Open = NVDA_Weekly$Open)
df_googl <- data.frame(Date = GOOGL_Weekly$Date, Open = GOOGL_Weekly$Open)
df_msft <- data.frame(Date = MSFT_Weekly$Date, Open = MSFT_Weekly$Open)
df_amzn <- data.frame(Date = AMZN_Weekly$Date, Open = AMZN_Weekly$Open)


# Split Data into Training and Test Sets
googl_train <- df_googl[c(1:470),]
googl_test <- df_googl[c(471:522),]

nvda_train <- df_nvda[c(1:470),]
nvda_test <- df_nvda[c(471:522),]

msft_train <- df_msft[c(1:470),]
msft_test <- df_msft[c(471:522),]

amzn_train <- df_amzn[c(1:470),]
amzn_test <- df_amzn[c(471:522),]


# Turn into time series
gtr <- ts(googl_train$Open, frequency = 52, start = c(2010, 1))
gte <- ts(googl_test$Open, frequency = 52, start = c(2019, 1))

ntr <- ts(nvda_train$Open, frequency = 52, start = c(2010, 1))
nte <- ts(nvda_test$Open, frequency = 52, start = c(2019, 1))

mtr <- ts(msft_train$Open, frequency = 52, start = c(2010, 1))
mte <- ts(msft_test$Open, frequency = 52, start = c(2019, 1))

atr <- ts(amzn_train$Open, frequency = 52, start = c(2010, 1))
ate <- ts(amzn_test$Open, frequency = 52, start = c(2019, 1))
```


Print summary of NVDA stock as reference
```{r}
print(summary(NVDA_Weekly))
```

Check the class of our dataset.
```{r}
class(NVDA_Weekly)
```

As shown above, we have a tibble dataframe of our stocks we read in from our 4 csv files of the NVDA, GOOGL, MSFT, and AMZN stocks, with column values corresponding to the dates price at stock open, close, as well as the low and high prices during open, and finally, the volume. Our dataset ranges from the beginning 2010 to the end of 2019, calculating the weekly open prices for each week.

```{r}
GOOGL_Weekly_Open_ts <- ts(GOOGL_Weekly$Open, start = c(2010, 1), frequency = 52)
NVDA_Weekly_Open_ts <- ts(NVDA_Weekly$Open, start = c(2010, 1), frequency = 52)
MSFT_Weekly_Open_ts <- ts(MSFT_Weekly$Open, start = c(2010, 1), frequency = 52)
AMZN_Weekly_Open_ts <- ts(AMZN_Weekly$Open, start = c(2010, 1), frequency = 52)
```


```{r, echo = F}
par(mfcol = c(2, 2))
plot(NVDA_Weekly_Open_ts, main="NVDA Weekly Open Share Price", xlab="Date", ylab="Share Price USD", sub="Stock Time Series", col.main='red', col.lab='blue', col.sub='black',font.main=4, font.lab=4, font.sub=4)

plot(GOOGL_Weekly_Open_ts, main="GOOGL Weekly Open Share Price", xlab="Date", ylab="Share Price USD", sub="Stock Time Series", col.main='red', col.lab='blue', col.sub='black',font.main=4, font.lab=4, font.sub=4)

plot(MSFT_Weekly_Open_ts, main="MSFT Weekly Open Share Price", xlab="Date", ylab="Share Price USD", sub="Stock Time Series", col.main='red', col.lab='blue', col.sub='black',font.main=4, font.lab=4, font.sub=4)

plot(AMZN_Weekly_Open_ts, main="AMZN Weekly Open Share Price", xlab="Date", ylab="Share Price USD", sub="Stock Time Series", col.main='red', col.lab='blue', col.sub='black',font.main=4, font.lab=4, font.sub=4)
```


Our tech stocks have in common a steady increase weekly from 2010 to 2020. 

Checking for NA values in our dataset:
```{r, echo = F}
data.frame(googl_isna = sum(is.na(GOOGL_Weekly$Open)),
           nvda_isna = sum(is.na(NVDA_Weekly$Open)),
           msft_isna = sum(is.na(MSFT_Weekly$Open)),
           amzn_isna = sum(is.na(AMZN_Weekly$Open)))
```


Constructing histograms:

```{r, echo = F}
par(mfrow = c(2,2))
hist(ntr)
hist(gtr)
hist(mtr)
hist(atr)
```


As we see from our histograms, we have highly skewed data and requiring a transformation to normalize. 

Use the Augmented Dickey-Fuller Test to check for stationarity in each stock
```{r, echo = F, warning = F}
library(tseries)
data.frame(GOOGL_ADF_P_VALUE = adf.test(gtr)$p.value,
           NVDA_ADF_P_VALUE = adf.test(ntr)$p.value,
           MSFT_ADF_P_VALUE = adf.test(mtr)$p.value,
           AMZN_ADF_P_VALUE = adf.test(atr)$p.value)
```

Using our adf tests, we can tell that all of our stocks are non-stationary processes, since they are above the significance value (p value > 0.05) and thus we fail to reject the non-stationarity null hypothesis.

## Transforming our Data to a Stationary Process

We will transform our dataset to remove our trend and seasonal components by performing a decomposition and extracting its residuals. First, we will get the first difference of our datasets because our data is non-stationary, and we need to remove our trends and seasonality. As we can see from our decomposition graphs, we clearly have a trend and seasonal aspect of our dataset:
```{r}
# Google's Decomposition plot
plot(decompose(gtr))

# Nvidia's Decomposition plot
plot(decompose(ntr))

# Microsoft's Decomposition plot
plot(decompose(mtr))

# Amazon's Decomposition plot
plot(decompose(atr))
```

We can see that we have a clear trend and seasonality from our decomposition. Our random also has a slight bit of pattern towards the end. This signals that we can difference further to stabilize the variance and remove further trends/seasonalities.

We must omit the NA values that were generated from the decomposition function. Since we have seasonality at a period of each year, we then find the loss at lag = 52 since we have 52 weeks in a year to see if we can remove our seasonality component. If not, we can test our arima vs sarima model and see if we have a lower AIC if we add in the seasonal component to our arima. 

```{r}
googl_residuals <- na.omit(decompose(gtr)$random) %>% diff(lag = 52)
nvda_residuals <- na.omit(decompose(ntr)$random) %>% diff(lag = 52)
msft_residuals <- na.omit(decompose(mtr)$random) %>% diff(lag = 52)
amzn_residuals <- na.omit(decompose(atr)$random) %>% diff(lag = 52)
```


Lets check our plots to see if there is a trend/stationarity in our residuals:

```{r, echo = F}

par(mfrow = c(2,2))
plot(googl_residuals)
abline(h = 0, col = 'red')

plot(nvda_residuals)
abline(h = 0, col = 'red')

plot(msft_residuals)
abline(h = 0, col = 'red')

plot(amzn_residuals)
abline(h = 0, col = 'red')
```
It seems our plots show some trends and seasonality. We can check other factors as well. 

ACF plots:
```{r}
par(mfrow = c(2,2))
acf(googl_residuals, lag.max = 100)
acf(nvda_residuals, lag.max = 100)
acf(msft_residuals, lag.max = 100)
acf(amzn_residuals, lag.max = 100)
```

Our acf plot suggest that we have non-stationarity since our values are always passing the significance blue dashed line level and not gradually decreasing to zero as lag increases. We can also check our pacf plot: 
```{r}
par(mfrow = c(2,2))
pacf(googl_residuals, lag.max = 100)
pacf(nvda_residuals, lag.max = 100)
pacf(msft_residuals, lag.max = 100)
pacf(amzn_residuals, lag.max = 100)
```

We have decaying pacf plots which is good for stationarity, but we need to be sure we have stationarity by differencing even further because the ACF's indicate non-stationarity.

```{r, echo = F}

googl_residuals_diff <- diff(googl_residuals)
nvda_residuals_diff <- diff(nvda_residuals)
msft_residuals_diff <- diff(msft_residuals)
amzn_residuals_diff <- diff(amzn_residuals)
```


Let's check our differenced plot to see if there are any trends or seasonality:

```{r, echo = F}
par(mfrow = c(2,2))
plot(googl_residuals_diff)
abline(h = 0, col = 'red')

plot(nvda_residuals_diff)
abline(h = 0, col = 'red')

plot(msft_residuals_diff)
abline(h = 0, col = 'red')

plot(amzn_residuals_diff)
abline(h = 0, col = 'red')
```



Looking at our first difference, we see a significant improvement in having a constant mean compared to our non-differenced residuals, in addition, our plot does not have any trend or seasonality appearance

We can check our ACF plots:
```{r}
par(mfrow = c(2,2))
acf(googl_residuals_diff, lag.max = 100)
acf(nvda_residuals_diff, lag.max = 100)
acf(msft_residuals_diff, lag.max = 100)
acf(amzn_residuals_diff, lag.max = 100)
```

We can see our acf plots are gradually converging to zero as lag increases, suggesting some sort of stationarity processes in our datasets, but could also suggest a hint of seasonality since there are spikes at the periods.

Running PACF tests
```{r}
par(mfrow = c(2,2))
pacf(googl_residuals_diff, lag.max = 100)
pacf(nvda_residuals_diff, lag.max = 100)
pacf(msft_residuals_diff, lag.max = 100)
pacf(amzn_residuals_diff, lag.max = 100)
```
Our PACF plots aren't decaying, and we see a small bit of seasonality. We can check our ADF and KPSS tests to double check for stationarity, and run our Arima model with a higher order of autoregression to account for the pacf plot.

We run our Augmented Dickey Fuller test on each of our differenced residuals
```{r, warning = F}
data.frame(GOOGL_ADF_P_VALUE = adf.test(googl_residuals_diff)$p.value,
           NVIDIA_ADF_P_VALUE = adf.test(nvda_residuals_diff)$p.value,
           MSFT_ADF_P_VALUE = adf.test(msft_residuals_diff)$p.value,
           AMZN_ADF_P_VALUE = adf.test(amzn_residuals_diff)$p.value)
```

The ADF test suggests that our datasets are all stationarity. We can make sure we do not have other types of non-stationarity by running the Kwiatkowski–Phillips–Schmidt–Shin (KPSS) test:


```{r, warning = F}
data.frame(GOOGL_kpss_P_VALUE = kpss.test(googl_residuals_diff)$p.value,
           NVIDIA_kpss_P_VALUE = kpss.test(nvda_residuals_diff)$p.value,
           MSFT_kpss_P_VALUE = kpss.test(msft_residuals_diff)$p.value,
           AMZN_kpss_P_VALUE = kpss.test(amzn_residuals_diff)$p.value)
```
Since our datsets pass both our ADF and KPSS tests for stationarity, we can fit our arima time series models on our datasets.

## Fitting our Arima models:

```{r, cache = T, echo = F}
library(forecast)
```

For our model, we will use the arima model without the seasonal component to see which models perform best. Our ranking metri will be using aic. 

GOOGLE MODELS:

```{r, cache = T, echo = F}
par(mfrow=c(1,2))
acf(googl_residuals_diff, lag.max = 110)
pacf(googl_residuals_diff, lag.max = 110)
```


For our google residuals diff parameters, where we have it differenced, we don't need to difference it further, and so d = 0. For our seasonal component, we can set P as 1.0 or 2.0 as they are significant at those seasonal periods as we see from our PACF graph. For Q, we would set it as 1 since we have a significant value at the 1.0 from the ACF graph. D = 0 since we do not need to get the seasonal difference. For q, we see a lot of values , where q can equal to 0, 1, 3, 10,... and p can equal 1, 3, 4, 6, 9,... and more, but to avoid overfitting our dataset and for computational sake, we can use the first significant value where p = 1 or q = 0 or 1 , as these values also gives us the best AIC. 

Therefore, here are our possibilities for our arima dataset for Google:
Sarima(p = 1 or 2,
       d = 0,
       q = 0 or 1,
       P = 1 or 2,
       D = 0,
       Q = 1)

```{r, cache = T, include = F, echo = F}
knitr::opts_chunk$set(cache = TRUE)

googl_model1 <- arima(googl_residuals, order=c(1,0,0), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)
googl_model2 <- arima(googl_residuals, order=c(1,0,1), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)
googl_model3 <- arima(googl_residuals, order=c(2,0,1), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)
```

After fine tuning our parameters, we ended up with the three best models: Arima(1, 0, 1)(1, 0, 1), Arima(1, 0, 0)(1, 0, 1), and Arima(2, 0, 1)(1, 0, 1)
```{r, echo = F}
print(data.frame(googl_model1$aic, googl_model2$aic, googl_model3$aic))
```

These are our best models using the arima and sarima packages. Note that two of the parameters are the same, but are from different packages and thus can be considered as different models.

We will now see what best fits our other datasets:

NVIDIA MODELS:

```{r, cache = T, echo = F}
par(mfrow=c(1,2))
acf(nvda_residuals_diff, lag.max = 110)
pacf(nvda_residuals_diff, lag.max = 110)
```


For our nvidia residuals diff parameters, where we have it differenced, we don't need to difference it further, and so d = 0. For our seasonal component, we can set P as 1.0 as they are significant at those seasonal periods as we see from our PACF graph. For Q, we would set it as 1 since we have a significant value at the 1.0 from the ACF graph. D = 0 since we do not need to get the seasonal difference. For p, we see a lot of values, where p can equal to 8, 9, 13,.. and q can equal 0, 8, 9,... and more, but to avoid overfitting our dataset and for computational sake we will consider the first three values of p and q

Therefore, here are our possibilities for our arima dataset for Nvidia:
Sarima(p = 8 or 9
       d = 0,
       q = 0, 7, or 8
       P = 1,
       D = 0,
       Q = 1)

```{r, cache = T, include = F, echo = F}
knitr::opts_chunk$set(cache = TRUE)

# we are getting a non-stationary error when we have d = 0 so we will consider when d = 1, and try to remove it further by differencing again:
nvda_model1 <- arima(nvda_residuals, order=c(9,1,8), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)
nvda_model2 <- arima(nvda_residuals, order=c(8,1,0), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)
nvda_model3 <- arima(nvda_residuals, order=c(8,1,7), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)

```

After fine tuning our data to get the best 3 AIC values, we ended up with the three best models: ARIMA(8, 0, 8)(1, 0, 1), AND ARIMA(9, 0, 8)(1, 0, 1), ARIMA(8, 0, 7)(1, 0, 1)
```{r, echo = F}
print(data.frame(nvda_model1$aic, nvda_model2$aic, nvda_model3$aic))
```


MICROSOFT MODELS:

```{r, cache = T, echo = F}
par(mfrow=c(1,2))
acf(msft_residuals_diff, lag.max = 110)
pacf(msft_residuals_diff, lag.max = 110)
```


For our msft residuals diff parameters, where we have it differenced, we don't need to difference it further, and so d = 0. For our seasonal component, we can set P as 1.0 or 2.0 as they are significant at those seasonal periods as we see from our PACF graph. For Q, we would set it as 1 since we have a significant value at the 1.0 from the ACF graph. D = 0 since we do not need to get the seasonal difference. For p, we see a lot of values, where p can equal to 1, 12, 14,.. and q can equal 0, 1, 6, 17,... and more, but to avoid overfitting our dataset and for computational sake, we will consider the first three values of p and q.

Therefore, here are our possibilities for our arima dataset for MICROSOFT:
Sarima(p = 1, 12, 14
       d = 0,
       q = 0, 1, 6, 17
       P = 1.0 or 2.0,
       D = 0,
       Q = 1)

```{r, cache = T, include = F, echo = F, warning = F}
knitr::opts_chunk$set(cache = TRUE)

msft_model1 <- arima(msft_residuals, order=c(12,0,6), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)
msft_model2 <- arima(msft_residuals, order=c(12,0,0), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)
msft_model3 <- arima(msft_residuals, order=c(12,0,1), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)
```

After fine tuning our data to get the best 3 AIC values, we ended up with the three best models: ARIMA(12, 0, 6)(1, 0, 1), ARIMA(12, 0, 0)(1, 0, 1), ARIMA(12, 0, 1)(1, 0, 1)
```{r, echo = F}
print(data.frame(msft_model1$aic, msft_model2$aic, msft_model3$aic))
```


AMAZON MODELS:

```{r, cache = T, echo = F}

par(mfrow=c(1,2))
acf(amzn_residuals_diff, lag.max = 110)
pacf(amzn_residuals_diff, lag.max = 110)
```


For our amazn residuals diff parameters, where we have it differenced, we don't need to difference it further, and so d = 0. For our seasonal component, we can set P as 1.0 or 2.0 as they are significant at those seasonal periods as we see from our PACF graph. For Q, we would set it as 1 since we have a significant value at the 1.0 from the ACF graph. D = 0 since we do not need to get the seasonal difference. For p, we see a lot of values, where p can equal to 8 and 10, 16,.. and q can equal 0, 8, 10,... and more, but to avoid overfitting our dataset and for computational sake we will consider the first three values of p and q.

Therefore, here are our possibilities for our arima dataset for AMAZON:
Sarima(p = 8 or 9,
       d = 0,
       q = 0, 8, or 9,
       P = 1.0 or 2.0,
       D = 0,
       Q = 1)
       
```{r, cache = T, include = F, echo = F, warning = F}
knitr::opts_chunk$set(cache = TRUE)

amzn_model1 <- arima(amzn_residuals, order=c(8,0,0), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)
amzn_model2 <- arima(amzn_residuals, order=c(8,0,0), seasonal=list(order=c(2,0,1), period=52), include.mean=FALSE)
amzn_model3 <- arima(amzn_residuals, order=c(9,1,0), seasonal=list(order=c(1,0,1), period=52), include.mean=FALSE)

```

After fine tuning our data to get the best 3 AIC values, we ended up with the three best models: 
ARIMA(8,0,0)(1,0,1)
ARIMA(8,0,0)(2,0,1)
ARIMA(9,0,0)(1,0,1)
```{r, echo = F, echo = F}
print(data.frame(amzn_model1$aic, amzn_model2$aic, amzn_model3$aic))
```

Now, we will test the residuals of our values to see if our models are reliable:

## Testing models' residuals

Our residuals should look like a normal white noise, and we can test this using a histogram.
```{r}
# Test for googl:
par(mfrow=c(2,2))
hist(googl_model1$residuals, breaks = 30)
hist(googl_model2$residuals, breaks = 30)
hist(googl_model3$residuals, breaks = 30)
```

```{r}
par(mfrow=c(2,2))
hist(nvda_model1$residuals, breaks = 30)
hist(nvda_model2$residuals, breaks = 30)
hist(nvda_model3$residuals, breaks = 30)
```


```{r}
par(mfrow = c(2,2))
hist(msft_model1$residuals, breaks = 30)
hist(msft_model2$residuals, breaks = 30)
hist(msft_model3$residuals, breaks = 30)
```


```{r}
par(mfrow = c(2,2))

hist(amzn_model1$residuals, breaks = 30)
hist(amzn_model2$residuals, breaks = 30)
hist(amzn_model3$residuals, breaks = 30)

```

Our histograms look normal and resembles a gaussian white noise distribution with the exception of NVIDIA, which is unaffected by our parameters set in our arima model. We can do another test by checking our acf and pacf graphs for all instances.


```{r, include = F}
g1 <- googl_model1$residuals
g2 <- googl_model2$residuals
g3 <- googl_model3$residuals

n1 <- nvda_model1$residuals
n2 <- nvda_model2$residuals
n3 <- nvda_model3$residuals

m1 <- msft_model1$residuals
m2 <- msft_model2$residuals
m3 <- msft_model3$residuals

a1 <- amzn_model1$residuals
a2 <- amzn_model2$residuals
a3 <- amzn_model3$residuals
```

LJUNG-BOX TEST and BOX-PIERCE TESTS
```{r, echo = F}
a <- cbind(rbind(box_pierce_googl_model1 <- Box.test(g1, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_googl_model2 <- Box.test(g2, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_googl_model3 <- Box.test(g3, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_nvda_model1 <- Box.test(n1, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_nvda_model2 <- Box.test(n2, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_nvda_model3 <- Box.test(n3, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_msft_model1 <- Box.test(m1, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_msft_model2 <- Box.test(m2, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_msft_model3 <- Box.test(m3, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_amzn_model1 <- Box.test(a1, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_amzn_model2 <- Box.test(a2, lag = 20, type = "Box-Pierce")$p.value,
           box_pierce_amzn_model3 <- Box.test(a3, lag = 20, type = "Box-Pierce")$p.value
           ),
rbind(box_pierce_googl_model1 <- Box.test(g1, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_googl_model2 <- Box.test(g2, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_googl_model3 <- Box.test(g3, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_nvda_model1 <- Box.test(n1, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_nvda_model2 <- Box.test(n2, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_nvda_model3 <- Box.test(n3, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_msft_model1 <- Box.test(m1, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_msft_model2 <- Box.test(m2, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_msft_model3 <- Box.test(m3, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_amzn_model1 <- Box.test(a1, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_amzn_model2 <- Box.test(a2, lag = 20, type = "Ljung-Box")$p.value,
           box_pierce_amzn_model3 <- Box.test(a3, lag = 20, type = "Ljung-Box")$p.value
           )
)
colnames(a) <- c('Box-Pierce', 'Ljung-Box')
rownames(a) <- c("g1","g2","g3","n1","n2","n3","m1","m2","m3","a1","a2","a3")
a
```

These are our box pierce test values from our dataset. 

PACFS AND ACF OF GOOGLE MODEL RESIDUALS: 

```{r, echo = F}
par(mfrow = c(2, 3))
acf(g1)
acf(g2)
acf(g3)
pacf(g1)
pacf(g2)
pacf(g3)
```

PACFS AND ACF OF NVIDIA MODEL RESIDUALS: 

```{r, echo = F}
par(mfrow = c(2, 3))
acf(n1)
acf(n2)
acf(n3)
pacf(n1)
pacf(n2)
pacf(n3)
```


PACFS AND ACF OF MICROSOFT MODEL RESIDUALS: 

```{r, echo = F}
par(mfrow = c(2, 3))
acf(m1)
acf(m2)
acf(m3)
pacf(m1)
pacf(m2)
pacf(m3)
```

PACFS AND ACF OF AMAZON MODEL RESIDUALS:

```{r, echo = F}
par(mfrow = c(2, 3))
acf(a1)
acf(a2)
acf(a3)
pacf(a1)
pacf(a2)
pacf(a3)
```

All in all, our pacf and acf charts for all of our stocks do not resemble a white noise distribution, and none of them pass our ljung box tests, no matter how we fine tune our models, which could be a result of our transformation that still had some trending/seasonality. This tells us that our models may not be as effective on our test data, but we can check by visualizing how our models perform on the test data of 2019.

## Forecasting:

#### Google Forecast:

```{r, echo = F}
knitr::opts_chunk$set(cache = TRUE)


par(mfrow = c(3, 1))
sarima.for(gtr, n.ahead=52 ,p=1, d=0, q=0, P=1, D=1, Q=1, S=52, main="Forecasting Google Stock for 2019")
lines(gte, col = 'blue', type="b")

sarima.for(gtr, n.ahead=52 ,p=1, d=0, q=1, P=1, D=1, Q=1, S=52, main="Forecasting Google Stock for 2019")
lines(gte, col = 'blue', type="b")

sarima.for(gtr, n.ahead=52 ,p=2, d=0, q=1, P=1, D=1, Q=1, S=52, main="Forecasting Google Stock for 2019")
lines(gte, col = 'blue', type="b")
```

#### Nvidia Forecast:

```{r, echo = F}
knitr::opts_chunk$set(cache = TRUE)

par(mfrow = c(3, 1))
sarima.for(ntr, n.ahead=52 ,p=1, d=0, q=1, P=1, D=1, Q=1, S=52, main="Forecasting Nvidia Stock for 2019")
lines(nte, col = 'blue', type="b")

sarima.for(ntr, n.ahead=52 ,p=1, d=0, q=0, P=1, D=1, Q=1, S=52, main="Forecasting Nvidia Stock for 2019")
lines(nte, col = 'blue', type="b")

sarima.for(ntr, n.ahead=52 ,p=1, d=0, q=2, P=1, D=1, Q=1, S=52, main="Forecasting Nvidia Stock for 2019")
lines(nte, col = 'blue', type="b")
```

#### Microsoft Forecast:

```{r, echo = F}
knitr::opts_chunk$set(cache = TRUE)

par(mfrow = c(3, 1))
sarima.for(mtr, n.ahead=52 ,p=12, d=0, q=6, P=1, D=1, Q=1, S=52, main="Forecasting Microsoft Stock for 2019")
lines(mte, col = 'blue', type="b")

sarima.for(mtr, n.ahead=52 ,p=12, d=0, q=0, P=1, D=1, Q=1, S=52, main="Forecasting Microsoft Stock for 2019")
lines(mte, col = 'blue', type="b")

sarima.for(mtr, n.ahead=52 ,p=12, d=0, q=1, P=1, D=1, Q=1, S=52, main="Forecasting Microsoft Stock for 2019")
lines(mte, col = 'blue', type="b")
```

#### Amazon Forecast:

```{r, echo = F}
knitr::opts_chunk$set(cache = TRUE)



par(mfrow = c(3, 1))
sarima.for(atr, n.ahead=52 ,p=8, d=0, q=0, P=1, D=1, Q=1, S=52, main="Forecasting Amazon Stock for 2019")
lines(ate, col = 'blue', type="b")

sarima.for(atr, n.ahead=52 ,p=8, d=0, q=0, P=1, D=2, Q=1, S=52, main="Forecasting Amazon Stock for 2019")
lines(ate, col = 'blue', type="b")

sarima.for(atr, n.ahead=52 ,p=9, d=1, q=0, P=1, D=1, Q=1, S=52, main="Forecasting Amazon Stock for 2019")
lines(ate, col = 'blue', type="b")
```

## Forecast Results, Findings, and Inferences: 

Our Google stock had a smooth line, so our prediction assumed that we did not have a seasonality and instead a gradual, positive trend. The arima model prediction was fairly close with Google's true value in blue until the 3rd quarter of 2019, when Google's stock increased much more than predicted. The same applies for all of our arima models fitted on the google dataset.

Our Nvidia stock forecast did manage to imitate the true values. However, it veered off trajectory in the 3rd quarter of 2019. Nevertheless, this is our second best prediction and it performed fairly well.

Our Microsoft stock prediction were far off from what we had predicted despite its stock having a steady increase. The forecast most likely used its current stagnant trend to make a prediction, which was when the stock decided to increase in price since the beginning of 2019. 

Our Amazon stock forecast was our most accurate forecast. Albeit having a stable trend, the prediction accurately determined its trajectory up until the end of 2020. Our 2nd Arima model correctly guessed the majority of Amazon's price trajectory throughout 2019. We can see that the true value was within our forecast's confidence bands for almost the entirety of the true values, though this is not much as these stocks are not very volatile. 

Overall, we can conclude that we did not achieve the forecasts that we wanted, but if we were to forecast our stocks, we would run our arima models on the Amazon stock for its predictability. It seemed our forecasts did also did not account for the fact that we had seasonality in our dataset. It seems the higher the values of our p, q, P, and Q, the lesser the accurate we are in our models. This could be due to the fact that we have overfit on our training set and thus performed poorly on the test set. We also have shown that we need to find a problem with either our transformation or our model, because we did not get gaussian white noise distributions from our residuals after we fit the data. All in all, the forecasts and models did not fit, but some made decent predictions, especially Amazon. We can also infer from the fact that these are incredibly stable stocks and not as volatile as other riskier stocks. Thus, we have a more stable true prediction which could contribute to having a good forecast
despite our evaluation of our models not being very strong.

There were other noticeable factors that could have played into our poor stock forecast as well. One was notably the US-China trade war, which began in mid-July which was towards the end of our training dataset. This event crippled the technology industry especially, with the industry being heavily reliant on labor and manufacturing parts from China.

## Conclusion: 

In conclusion, our analysis of the weekly stock prices for four of the largest technology companies in the world over a 10-year period from 2010 to 2020 has provided us with interesting insights into the performance of these stocks. Our main objective was to determine which of the four stocks would have the highest predicted performance in the year 2019, and thus we used ARIMA models to make predictions.

After analyzing the data and comparing our predictions to the true values, we found that our models did not perform as accurately as we had hoped. Our Google stock had a smooth line, and our prediction assumed that we did not have seasonality, but our ARIMA model was fairly close until the 3rd quarter of 2019, when Google's stock increased more than predicted. Our Nvidia stock forecast managed to imitate the true values until it veered off course towards the 3rd quarter of 2019 as well, but our Microsoft stock prediction was far off from what we had predicted despite its stock having a steady increase. Finally, our Amazon stock forecast was our most accurate forecast, with the second ARIMA model making correct predictions of the stock's price trajectory throughout 2019.

We can conclude that our ARIMA models did not perform as accurately as we had hoped, but our analysis did provide us with some valuable insights. For instance, we observed that Amazon was the most predictable stock among the four, and thus it could be an excellent choice for investors who wish to invest in individual stocks from the technology industry.

Overall, our analysis highlighted the importance of using statistical models to make stock predictions, especially in industries as dynamic as the technology sector. While our models did not provide us with the accuracy we were hoping for, it is still a valuable exercise in understanding the nuances of the stock market and making informed investment decisions. Future analyses could include more factors and consider the impact of major events on the stocks, such as pandemics, economic crises, and geopolitical tensions.



## Appendix:

Datasets retrieved from Yahoo Finance:

Amazon. (n.d.). Retrieved from https://finance.yahoo.com/quote/AMZN/history?p=AMZN

Microsoft. (n.d.). Retrieved from https://finance.yahoo.com/quote/MSFT/history?p=MSFT

Nvidia. (n.d.). Retrieved from https://finance.yahoo.com/quote/NVDA/history?p=NVDA

Google. (n.d.). Retrieved from https://finance.yahoo.com/quote/GOOGL/history?p=GOOGL


